---
title: "Untitled"
author: "Eric Hirsch"
date: "12/13/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(kernlab)
library(readr)
library(caret)
library(tidyverse)
library(gridExtra)
library(janitor)
library(Matrix)
```

#### 1. Using the training.csv file, plot representations of the first 10 images to understand the data format. Go ahead and divide all pixels by 255 to produce values between 0 and 1. (This is equivalent to min-max scaling.) (5 points)

a. Read Data

```{r}

location = "work"

if (location=="work")
{
  mnist_raw <- read.csv("C:\\Users\\eric.hirsch\\Desktop\\RStudio\\605_Final\\Final\\MNIST.csv",header=TRUE)
} else if (loccation=="laptop")
  
{
  mnist_raw <- read.csv("D:\\RStudio\\CUNY_605\\Final\\MNIST.csv",header=TRUE)
} else
  
{
  mnist_raw <- read.csv("D:\\RStudio\\605_Final\\Final\\MNIST.csv",header=TRUE)
}

```

b. Scale Table
```{r}

mnist <- mnist_raw
colnames(mnist)[1]<-"Digit"
mnist[is.na(mnist)] <- 0

mnist_sample <- mnist[sample(nrow(mnist), 5000), ]
mnist_norm<-as.matrix(mnist[,-1]/255)

```

c. Plot the first 10 images

```{r}

for (i in 1:10)
{
im2<-matrix((mnist[i,2:ncol(mnist)]), nrow=28, ncol=28) 
im_numbers <- apply(im2, 2, as.numeric)
image(1:28, 1:28, im_numbers, col=gray((0:255)/255))
}

```

2. What is the frequency distribution of the numbers in the dataset? (5 points)

```{r}

tabyl(mnist, Digit)

# Don't map a variable to y
ggplot(mnist, aes(x=factor(Digit)))+
  geom_bar(stat="count")
```

The digits are fairly uniformly distributed, with 1s being the most represented (11.1%) and 5s the least (9.0%).

5. For each number, provide the mean pixel intensity. What does this tell you? (5 points)

```{r}

dfMeans <- mnist
dfMeans$Mean <- apply(dfMeans[,2:785], 1, mean)

dfMeans2 <- dfMeans %>%
  group_by(Digit) %>%
  summarize(NumMean = mean(Mean))
dfMeans2
```

This tells us the relative space a number occupies within its matrix.  We can see that the number 1, a simple line, occupies the least space. The seven, which is a line with a small attached segment, occupies somewhat more space.  In contrast, the intensity of zero is more than twice that of 1, suggesting it occupies a lot of space. When we finish the analysis, it would be interesting to see whether there is more confusion between digits that occupy similar amounts of space.

#### Reduce the data by using principal components that account for 95% of the variance. How many components did you generate? Use PCA to generate all possible components (100% of the variance). How many components are possible? Why? (5 points) 

```{r}

#Perform PCA on the scaled matrix
mnist_norm_cov <- cov(mnist_norm)
pca <- prcomp(mnist_norm_cov)
```

```{r}

# Show the cumulative variance
variance_explained <- as.data.frame(pca$sdev^2/sum(pca$sdev^2))

variance_explained <- cbind(c(1:784),variance_explained,cumsum(variance_explained[,1]))

colnames(variance_explained) <- c("n","individual_var_explained","cumulative_var_explained")

variance_explained

ggplot(variance_explained, aes(n, cumulative_var_explained)) +
  geom_point()
```

I needed 20 components to account for 95% of the variance.  
At 536 components, additional components no longer increase the variance explained. As for the total components actually possible, this there would be 784 - unless there is collinearity, in which case there would be fewer.

#### 7. Plot the first 10 images generated by PCA. They will appear to be noise. Why? (5 points)

```{r}

# reconstruct matrix
restr <- pca$x[,1:4] %*% t(pca$rotation[,1:4])

# unscale and uncenter the data
if(pca$scale != FALSE){
  restr <- scale(restr, center = FALSE , scale=1/pca$scale)
}
if(all(pca$center != FALSE)){
  restr <- scale(restr, center = -1 * pca$center, scale=FALSE)
}

for (i in 1:10)
{

par(mfcol=c(1,2), mar=c(1,1,2,1))
    
im2<-matrix((mnist[i,2:ncol(mnist)]), nrow=28, ncol=28) 
im_numbers <- apply(im2, 2, as.numeric)
image(1:28, 1:28, im_numbers, col=gray((0:255)/255))

rst <- matrix(data=rev(restr[i,]), nrow=28, ncol=28)
image(1:28, 1:28, rst, col=gray((0:255)/255))

}

```

PVC does not ccount for digit groupings, so these images are a mix of all digits - they capture the sort of average uber digit, which mystically enough looks like a zero.

Now if we filter just for the digit 8:

```{r}


dfmnist <- as.data.frame(mnist)
mnist3 <- dfmnist %>%
  filter(Digit==8)

#mnist4 <- mnist3[sample(nrow(mnist3), 5000), ]  
colnames(mnist3)[1]<-"Digit"
mnist3[is.na(mnist3)] <- 0


mnist_norm4<-as.matrix(mnist3[,-1])/255

mnist_norm_cov2 <- cov(mnist_norm4)
pca2 <- prcomp(mnist_norm_cov2)

#Reconstruct the result
restr <- pca2$x[,1:4] %*% t(pca2$rotation[,1:4])

par(mfcol=c(1,2), mar=c(1,1,2,1))

for (i in 1:10)
{

im2<-matrix((mnist3[i,2:ncol(mnist3)]), nrow=28, ncol=28) 
im_numbers <- apply(im2, 2, as.numeric)
image(1:28, 1:28, im_numbers, col=gray((0:255)/255))

rst <- matrix(data=rev(restr[i,]), nrow=28, ncol=28)
image(1:28, 1:28, rst, col=gray((0:255)/255))

}

```

Build a multinomial model on the entirety of the training set. Then provide
its classification accuracy (percent correctly identified) as well as a matrix of observed versus
forecast values (confusion matrix). This matrix will be a 10 x 10, and correct classifications will
be on the diagonal. (10 points)

```{r}

# Loading the nnet package
require(nnet)

mnist_raw[is.na(mnist_raw)] <- 0
mnist_scaled1 <- as.data.frame(mnist_raw/255)
mnist_scaled1[,1] <- mnist_raw[,1]
colnames(mnist_scaled1)[1]<-"Digit"
mnist_sample <- mnist_scaled1[sample(nrow(mnist_raw), 1000), ]  
```
```{r}
# Training the multinomial model
#m_1 <- multinom(Digit ~ ., data=mnist_scaled1, MaxNWts =1000000, maxit=1000)
m_1 <- multinom(Digit ~ ., data=mnist_scaled1, MaxNWts =1000000, maxit=10)
```
```{r}

# Checking the model
#summary(m_1)
```

```{r}
training_pred <- predict(m_1, mnist_sample)
```

Confusion matrix

```{r}
tab <- table(training_pred, mnist_sample$Digit)
tab
```

Accuracy
```{r}
sum(diag(tab))/sum(tab)

```
